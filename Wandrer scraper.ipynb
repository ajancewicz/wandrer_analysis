{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4556ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports used:\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "#not yet used, but imported:\n",
    "from urllib.request import urlopen\n",
    "import mechanicalsoup\n",
    "import time\n",
    "from requests.auth import HTTPBasicAuth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12831339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my specific credentials for login\n",
    "with open('payload.py', 'r') as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259a799",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a specific session\n",
    "with requests.session() as s: \n",
    "    \n",
    "    #use GET command to find the authenticity token within the login url\n",
    "    req = s.get(login_url).text \n",
    "    html = BeautifulSoup(req,\"html.parser\") \n",
    "    token = html.find(\"input\", {\"name\": \"authenticity_token\"}).attrs[\"value\"] \n",
    "\n",
    "    #use my specific authenticity token plus credentials to access my account\n",
    "    payload = { \n",
    "        \"authenticity_token\": token, \n",
    "        'athlete[email]': login, \n",
    "        'athlete[password]': password, \n",
    "    }\n",
    "    \n",
    "    #response following posting my data to the location above\n",
    "    res = s.post(login_url, data=payload) \n",
    "\n",
    "#report outcome of login activity\n",
    "if res.ok or res.status_code == 302:\n",
    "    redirected_url = res.url\n",
    "    print(\"Login successful\", res.status_code, redirected_url)\n",
    "else:\n",
    "    print(\"Login failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f00cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the contents of the dashboard site\n",
    "r = s.get(dashboard_url) \n",
    "soup = BeautifulSoup (r.content, \"html.parser\")\n",
    "print(dashboard_url, soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e44670c",
   "metadata": {},
   "source": [
    "* All code above is used to locate, open, and read the wandrer.earth data. This must be executed properly before moving forward.\n",
    "* `soup` is now a variable containing the html content of the site `dashboard_url`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make lists to add the region and progress data\n",
    "region_gb_list = []\n",
    "region_name_list = []\n",
    "region_gps_list = []\n",
    "\n",
    "region_completed_list = []\n",
    "region_progress_list = []\n",
    "\n",
    "#Find all elements with the class \"achievement_row\"\n",
    "#In addition to locations, this will also check date achievements, but I can drop those in the df later\n",
    "achievement_rows = soup.find_all(class_=\"achievement_row\")\n",
    "\n",
    "#set counters to check NaNs\n",
    "no_name = 0\n",
    "no_gb = 0\n",
    "no_gps = 0\n",
    "\n",
    "#iterate through each achievement row\n",
    "for achievement_row in achievement_rows:\n",
    "    #extract location text\n",
    "    #if section has name, use that, then check missing name, otherwise 'N/A'\n",
    "    \n",
    "    present_name_element = achievement_row.select_one('.achievement_name')\n",
    "    missing_name_element = achievement_row.select_one('.missing_achievement_name')\n",
    "\n",
    "    if present_name_element:\n",
    "        achievement_name = present_name_element.text\n",
    "        \n",
    "    elif missing_name_element:\n",
    "        achievement_name = missing_name_element.text\n",
    "    else:\n",
    "        achievement_name = 'N/A'\n",
    "        no_name = no_name + 1\n",
    "    \n",
    "    region_name_list.append(achievement_name)\n",
    "        \n",
    "    # Extract \"gb ID\" value\n",
    "    data_gb_element = achievement_row.select_one('.geom_toggle')\n",
    "    data_gb_value = data_gb_element['data-gb'] if data_gb_element else \"N/A\"\n",
    "    if data_gb_value == \"N/A\":\n",
    "        no_gb = no_gb + 1\n",
    "    region_gb_list.append(data_gb_value)\n",
    "\n",
    "    # Extract coordinates from the data-diagonal attribute\n",
    "    data_diagonal_element = achievement_row.select_one('.geom_toggle')\n",
    "    coordinates = eval(data_diagonal_element['data-diagonal'])['coordinates'] if data_diagonal_element else \"N/A\"\n",
    "    if coordinates == \"N/A\":\n",
    "        no_gps = no_gps + 1\n",
    "    region_gps_list.append(coordinates)\n",
    "\n",
    "    #print(\"Location:\", achievement_name)\n",
    "    #print(\"Data-gb Value:\", data_gb_value)\n",
    "    #print(\"Coordinates:\", coordinates)\n",
    "    #print(\"------------------------\")\n",
    "\n",
    "#show the number of missing values vs. found values\n",
    "print(f\"GB IDs \\n missing: {no_gb}, present: {len(region_gb_list)-no_gb}\")\n",
    "print(f\"Names: \\n missing: {no_name}, present: {len(region_name_list)-no_name}\")\n",
    "print(f\"Coordinates \\n missing: {no_gps}, present: {len(region_gps_list)-no_gps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767d8d8f",
   "metadata": {},
   "source": [
    "There are 172 valid Name calls, but only 162 valid Regions. The name calls are likely non-location achievements, which will be dropped in the subsequent df.\n",
    "\n",
    "Next, I'll scrape sub-sites for each GB value to find the total distance available by plugging the GB value into a url and retrieving the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc036158",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in region_gb_list:\n",
    "    gb_url = ('https://wandrer.earth/geometry_badges/'+i)\n",
    "    r = s.get(gb_url) \n",
    "    sub_soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    total_span = sub_soup.find('span', string=lambda s: 'km total length' in s)\n",
    "    text = lambda f: f if f else 'NA'\n",
    "\n",
    "    print(text(total_span))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa1045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare lists for data on distances:\n",
    "#(by including the code in this block, it will prevent overloading redundant data in these lists if the code is re-run)\n",
    "region_foot_distance_list = []\n",
    "region_bike_distance_list = []\n",
    "region_total_distance_list = []\n",
    "\n",
    "#look for the summary pages of each of the regions represented by the gb codes, by scraping their individual URLs.\n",
    "for i in region_gb_list:\n",
    "    gb_url = ('https://wandrer.earth/geometry_badges/'+i)\n",
    "    r = s.get(gb_url) \n",
    "    sub_soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "#retrieve the total distance on bike, foot, and total.\n",
    "#some gb areas do not have breakdown by bike and foot, assume the total is equal to the distance on bike or foot.\n",
    "\n",
    "    #foot distance\n",
    "    foot_span = sub_soup.find('span', string=lambda s: 'foot' in s)\n",
    "\n",
    "    #bike distance\n",
    "    bike_span = sub_soup.find('span', string=lambda s: 'bike' in s)\n",
    "    \n",
    "    #total distance\n",
    "        #this is an interesting case, because when bike and run distances are not presented, the string is different.\n",
    "        #use an if statement to look for cases with all 3 listed, and else find the single total value.\n",
    "    if sub_soup.find('span', string=lambda s: 'total length' in s):\n",
    "        total_span = sub_soup.find('span', string=lambda s: 'total length' in s)\n",
    "    else: total_span = sub_soup.find('span', string=lambda s: 'km. Worth' in s)\n",
    "\n",
    "    #convert foot, bike, or total found in html to TEXT, strip excess characters\n",
    "    text = lambda f: f.get_text().strip().replace(',', '') if f else 'NA'\n",
    "    \n",
    "    #Append the distances to new lists\n",
    "    region_foot_distance_list.append(text(foot_span))\n",
    "    region_bike_distance_list.append(text(bike_span))\n",
    "    region_total_distance_list.append(text(total_span))\n",
    "\n",
    "    print(f'{gb_url} \\n    {text(foot_span)},\\n    {text(bike_span)},\\n    {text(total_span)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989fba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [region_gb_list, region_name_list, region_gps_list, region_foot_distance_list, region_bike_distance_list, region_total_distance_list]:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8080eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'GB code': region_gb_list, 'Locations': region_name_list, 'Coordinates': region_gps_list}\n",
    "df = pd.DataFrame(data)\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5823f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the time achievement rows\n",
    "df.drop(df[df['GB code'] == 'N/A'].index, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3180d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Foot'] = region_foot_distance_list\n",
    "df['Bike'] = region_bike_distance_list\n",
    "df['Total distance'] = region_total_distance_list\n",
    "df.shape, df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3499b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d095c7",
   "metadata": {},
   "source": [
    "The dataframe has been successfully created, the desired columns are present, and the information appears correct based on manual inspection of my account info online.\n",
    "\n",
    "The data is all object type. The following updates are needed:\n",
    "\n",
    "Column | Change needed\n",
    "-|-\n",
    "<b>GB code</b> | change to `int` dtype\n",
    "<b>Locations</b> | none\n",
    "<b>Coordinates</b> | 1. change to series dtype, 2 calculate midpoint, 3. change to `float` dtype\n",
    "<b>Foot</b></b> | split to new columns: distance, points. Trim text and change to `float` dtype\n",
    "<b>Bike</b> | split to new columns: distance, points. Trim text and change to `float` dtype\n",
    "<b>Total distance</b> |split to new columns: distance, points. Trim text and change to `float` dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18da951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the GB code to float\n",
    "df['GB code'] = df['GB code'].astype('float64')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0972cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08252a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfcoords = pd.DataFrame(df['Coordinates'].tolist(), index=df.index)\n",
    "dfcoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9824f1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Define a function to convert the string to a list of coordinates\n",
    "def parse_coordinates(coord_str):\n",
    "    coords = json.loads(coord_str)  # Using eval to convert the string to a list\n",
    "    return pd.Series(coords)\n",
    "\n",
    "# Apply the function to the 'Coordinates' column and expand into separate columns\n",
    "df[['Longitude1', 'Latitude1', 'Longitude2', 'Latitude2']] = df['Coordinates'].apply(parse_coordinates)\n",
    "\n",
    "# Drop the original 'Coordinates' column if needed\n",
    "#df = df.drop('Coordinates', axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inprogress_df = df.copy()\n",
    "inprogress_df['Progress'] = inprogress_df['Progress'].astype(float)\n",
    "inprogress_df['Region'] = inprogress_df['Region'].astype(str)\n",
    "inprogress_df = inprogress_df[~inprogress_df['Region'].str.contains('2023')]\n",
    "inprogress_df.sort_values(by='Progress', inplace=True)\n",
    "inprogress_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24580a7c",
   "metadata": {},
   "source": [
    "Next, \n",
    "1. find the total distance of the given `Region`\n",
    "2. IF \n",
    " * distance >75%, find <u>the distance required to complete (>99%) region</u>\n",
    " * distance >50%, find <u>the distance required to move to >75%</u>\n",
    " * distance >25%, find <u>the distance required to move to >50%</u>\n",
    " * distance <25%, find <u>the distance required to move to >25%</u>\n",
    "3. find the distance of regions that haven't been started required to move to 25%\n",
    "4. sort by shortest distance to completion for the region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a4752",
   "metadata": {},
   "source": [
    "import re\n",
    "\n",
    "for region in regions:\n",
    "    \n",
    "    # Extract text content from the div element\n",
    "    region_text = region.get_text(separator=' ', strip=True)\n",
    "\n",
    "    # Use regular expression to find the distance on foot\n",
    "    match = re.search(r'(\\d+\\.\\d+)\\s*km on foot', region_text)\n",
    "\n",
    "    if match:\n",
    "        distance_value = match.group(1)\n",
    "        print(distance_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66707a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify the region distance element from the popup info on each region\n",
    "region_code_list = []\n",
    "region_code = r.find('a', {'class': 'fa fa-info-circle info-circle', 'href': '#', 'data-bs-toggle': 'modal'})\n",
    "\n",
    "#look for progress\n",
    "if region_progress_element:\n",
    "    progress_bar = region_progress_element.find('div', class_='progress-bar')\n",
    "    region_progress = progress_bar['aria-valuenow']\n",
    "    region_progress_values.append(region_progress)\n",
    "    #print(f\"Region: {region_name}     Progress: {region_progress}% \\n\")\n",
    "else: region_progress_values.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0e458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find number code for regions and return ID\n",
    "if region_distance_element:\n",
    "    region_distance = region_distance_element.text.strip()\n",
    "\n",
    "    #add region name to list\n",
    "    region_distances.append(region_distance)\n",
    "else: print('none found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a712331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make list to add the total region distance data\n",
    "region_distances = []\n",
    "\n",
    "for r in regions:\n",
    "    distance_span = r.find('span', string=lambda s: 'km on foot' in s)\n",
    "    \n",
    "    if distance_span:\n",
    "        # Extract the distance value\n",
    "        distance_text = distance_span.get_text(strip=True)\n",
    "        distance_value = distance_text.split()[0]  # Extract the numeric value\n",
    "        print(distance_value)\n",
    "    else:\n",
    "        print(\"Distance on foot not found.\")\n",
    "    \n",
    "    #find regions and return distance\n",
    "    #if distance_element:\n",
    "        #region_distance = distance_element.text.strip()\n",
    "        \n",
    "        #add region name to list\n",
    "        #region_distances.append(region_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d7a5a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inprogress_df['Level_Up'] = 0.0\n",
    "\n",
    "for index, row in inprogress_df.iterrows():\n",
    "    progress = row['Progress']\n",
    "    if progress >= 99.0:\n",
    "        0\n",
    "    elif progress >= 90.0:\n",
    "        inprogress_df.at[index, 'Level_Up'] = 99.0 - progress\n",
    "    elif progress >= 75.0:\n",
    "        inprogress_df.at[index, 'Level_Up'] = 90.0 - progress\n",
    "    elif progress >= 50.0:\n",
    "        inprogress_df.at[index, 'Level_Up'] = 75.0 - progress\n",
    "    elif progress >= 25.0:\n",
    "        inprogress_df.at[index, 'Level_Up'] = 50.0 - progress\n",
    "    else:\n",
    "        inprogress_df.at[index, 'Level_Up'] = 25.0 - progress\n",
    "        \n",
    "inprogress_df.sort_values(by='Level_Up', inplace=True)\n",
    "inprogress_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb171c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'Progress' column exists in your DataFrame\n",
    "# Create a DataFrame for demonstration purposes\n",
    "dataa = {'Progress': [80, 60, 45, 30, 20]}\n",
    "inprogres_df = pd.DataFrame(dataa)\n",
    "\n",
    "# Apply the conditions and create the 'Level_Up' column\n",
    "inprogres_df['Level_Up'] = 0  # Initialize the column with zeros\n",
    "\n",
    "# Update the values based on conditions\n",
    "inprogres_df.loc[inprogres_df['Progress'] >= 90, 'Level_Up'] = 100 - inprogres_df['Progress']\n",
    "inprogres_df.loc[(inprogres_df['Progress'] >= 75) & (inprogres_df['Progress'] < 90), 'Level_Up'] = 90 - inprogress_df['Progress']\n",
    "inprogres_df.loc[(inprogres_df['Progress'] >= 50) & (inprogres_df['Progress'] < 75), 'Level_Up'] = 75 - inprogress_df['Progress']\n",
    "inprogres_df.loc[(inprogres_df['Progress'] >= 25) & (inprogres_df['Progress'] < 50), 'Level_Up'] = 50 - inprogress_df['Progress']\n",
    "inprogres_df.loc[inprogres_df['Progress'] < 25, 'Level_Up'] = 25 - inprogres_df['Progress']\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(inprogres_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bscapstone",
   "language": "python",
   "name": "bscapstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
