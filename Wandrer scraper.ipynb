{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17211e7e",
   "metadata": {},
   "source": [
    "# Wandrer scraper\n",
    "\n",
    "This code utilizes my account at [wandrer.earth] to identify regions where I have traveled in order top optimize game points for distance traveled within specific regions. The code is intended to do the following:\n",
    "\n",
    "\n",
    "1. Differentiate between foot, bike, or total achievement\n",
    "2. Identify regions where I have the least distance to a milestone (25%, 50%, 75%, 90%, or 99% completion)\n",
    "3. Report a map with locations on transit closest to the given distance\n",
    "    1. Show a map with a 2.5k and 5k diameter around my common hubs   \n",
    "        1. Kids' activities\n",
    "        2. Transit stops\n",
    "    2. Overlay map with the key areas closest to completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4556ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports used:\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#not yet used, but imported:\n",
    "from urllib.request import urlopen\n",
    "import mechanicalsoup\n",
    "import time\n",
    "from requests.auth import HTTPBasicAuth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bfc10c",
   "metadata": {},
   "source": [
    "`payload.py` contains my login (secret), password (secret), login_url (https://wandrer.earth/signin), and dashboard_url (secret)\n",
    "\n",
    "The code below opens and reads my payload file and initiates a session in my account at wandrer.earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12831339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my specific credentials for login\n",
    "with open('payload.py', 'r') as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b259a799",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful 200 https://wandrer.earth/dashboard\n"
     ]
    }
   ],
   "source": [
    "#create a specific session\n",
    "with requests.session() as s: \n",
    "    \n",
    "    #use GET command to find the authenticity token within the login url\n",
    "    req = s.get(login_url).text \n",
    "    html = BeautifulSoup(req,\"html.parser\") \n",
    "    token = html.find(\"input\", {\"name\": \"authenticity_token\"}).attrs[\"value\"] \n",
    "\n",
    "    #use my specific authenticity token (which is scraped from the site) plus credentials (from the payload file) to access my account\n",
    "    payload = { \n",
    "        \"authenticity_token\": token, \n",
    "        'athlete[email]': login, \n",
    "        'athlete[password]': password, \n",
    "    }\n",
    "    \n",
    "    #response following posting my data to the location above\n",
    "    res = s.post(login_url, data=payload) \n",
    "\n",
    "#report outcome of login activity\n",
    "if res.ok or res.status_code == 302:\n",
    "    redirected_url = res.url\n",
    "    print(\"Login successful\", res.status_code, redirected_url)\n",
    "else:\n",
    "    print(\"Login failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe14733d",
   "metadata": {},
   "source": [
    "A `200` code indicates successful login to my dashboard. I next scrape the information from the dashboard to find regions, distances, and percent completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f00cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the contents of the dashboard site\n",
    "r = s.get(dashboard_url) \n",
    "soup = BeautifulSoup (r.content, \"html.parser\")\n",
    "print(dashboard_url, soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e44670c",
   "metadata": {},
   "source": [
    "* All code above is used to locate, open, and read the wandrer.earth data. This must be executed properly before moving forward.\n",
    "* `soup` is now a variable containing the html content of the site `dashboard_url`\n",
    "\n",
    "Next, I make lists to hold the region gb code, which allows for opening the specific achievement site and retrieving foot, bike, and total distance numbers. Additionally, lists will hold region name and the gps coordinates for their location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e70bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "region_gb_list = []\n",
    "region_name_list = []\n",
    "region_gps_list = []\n",
    "region_progress_list = []\n",
    "\n",
    "# Set counters to track missing values\n",
    "no_name = 0\n",
    "no_gb = 0\n",
    "no_gps = 0\n",
    "no_progress = 0\n",
    "\n",
    "# Find all elements with the class \"achievement_row\"\n",
    "achievement_rows = soup.find_all(class_=\"achievement_row\")\n",
    "\n",
    "#iterate through each achievement row\n",
    "for achievement_row in achievement_rows:\n",
    "    #extract location text\n",
    "    #if section has name, use that, then check missing name, otherwise 'N/A'\n",
    "    \n",
    "    present_name_element = achievement_row.select_one('.achievement_name')\n",
    "    missing_name_element = achievement_row.select_one('.missing_achievement_name')\n",
    "\n",
    "    if present_name_element:\n",
    "        achievement_name = present_name_element.text\n",
    "        \n",
    "    elif missing_name_element:\n",
    "        achievement_name = missing_name_element.text\n",
    "    \n",
    "    else:\n",
    "        achievement_name = 'N/A'\n",
    "        no_name = no_name + 1\n",
    "    \n",
    "    region_name_list.append(achievement_name)\n",
    "    \n",
    "    # Extract \"gb ID\" value\n",
    "    data_gb_value = achievement_row.select_one('.geom_toggle')['data-gb'] if achievement_row.select_one('.geom_toggle') else \"N/A\"\n",
    "    if data_gb_value == \"N/A\":\n",
    "        no_gb += 1\n",
    "    region_gb_list.append(data_gb_value)\n",
    "\n",
    "    # Extract coordinates\n",
    "    coordinates = eval(achievement_row.select_one('.geom_toggle')['data-diagonal'])['coordinates'] if achievement_row.select_one('.geom_toggle') else \"N/A\"\n",
    "    if coordinates == \"N/A\":\n",
    "        no_gps += 1\n",
    "    region_gps_list.append(coordinates)\n",
    "    \n",
    "    # Extract progress\n",
    "    progress_element = achievement_row.select_one('.progress-bar')\n",
    "    progress = progress_element['style'].split(':')[1].strip('%;') if progress_element else \"N/A\"\n",
    "    if progress == \"N/A\":\n",
    "        no_progress += 1\n",
    "    region_progress_list.append(progress)\n",
    "\n",
    "# Show the number of missing values vs. found values\n",
    "print(f\"GB IDs\\n Missing: {no_gb}, Present: {len(region_gb_list) - no_gb}\")\n",
    "print(f\"Names\\n Missing: {no_name}, Present: {len(region_name_list) - no_name}\")\n",
    "print(f\"Coordinates\\n Missing: {no_gps}, Present: {len(region_gps_list) - no_gps}\")\n",
    "print(f\"Foot Progress\\n Missing: {no_progress}, Present: {len(region_progress_list) - no_progress}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767d8d8f",
   "metadata": {},
   "source": [
    "There are 173 valid Name calls, but only 162 valid Regions. The name calls are likely non-location achievements, which will be dropped in the subsequent df.\n",
    "\n",
    "Next, I'll scrape sub-sites for each GB value to find the total distance available by plugging the GB value into a base url for the geometry badges, and retrieving the result. This is done by using `region_gb_list` to create a new list, `num_region_gb_list`, containing only regions that are floats (have geometry for location)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269c1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a list for only numeric gb entries\n",
    "num_region_gb_list = [x for x in region_gb_list if 'N/A' not in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f45733",
   "metadata": {},
   "source": [
    "The code in the next cell searches through each item in the `num_region_gb_list`, plugs it into the base url, gets the soup and parses, looking for that region's distance on foot, bike, and total. Because some regions only have total distance, I account for that in the total distance search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa1045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare lists for data on distances:\n",
    "#(by including the code in this block, it will prevent overloading redundant data in these lists if the code is re-run)\n",
    "region_foot_distance_list = []\n",
    "region_bike_distance_list = []\n",
    "region_total_distance_list = []\n",
    "\n",
    "#look for the summary pages of each of the regions represented by the gb codes, by scraping their individual URLs.\n",
    "for i in num_region_gb_list:\n",
    "    gb_url = ('https://wandrer.earth/geometry_badges/'+i)\n",
    "    r = s.get(gb_url) \n",
    "    sub_soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "#retrieve the total distance on bike, foot, and total.\n",
    "#some gb areas do not have breakdown by bike and foot, assume the total is equal to the distance on bike or foot.\n",
    "\n",
    "    #foot distance\n",
    "    foot_span = sub_soup.find('span', string=lambda s: 'foot' in s)\n",
    "\n",
    "    #bike distance\n",
    "    bike_span = sub_soup.find('span', string=lambda s: 'bike' in s)\n",
    "    \n",
    "    #total distance\n",
    "        #this is an interesting case, because when bike and run distances are not presented, the string is different.\n",
    "        #use an if statement to look for cases with all 3 listed, and else find the single total value.\n",
    "    if sub_soup.find('span', string=lambda s: 'total length' in s):\n",
    "        total_span = sub_soup.find('span', string=lambda s: 'total length' in s)\n",
    "    else: total_span = sub_soup.find('span', string=lambda s: 'km. Worth' in s)\n",
    "\n",
    "    #convert foot, bike, or total found in html to TEXT, strip excess characters\n",
    "    text = lambda f: f.get_text().strip().replace(',', '') if f else 'NA'\n",
    "    \n",
    "    #Append the distances to new lists\n",
    "    region_foot_distance_list.append(text(foot_span))\n",
    "    region_bike_distance_list.append(text(bike_span))\n",
    "    region_total_distance_list.append(text(total_span))\n",
    "\n",
    "    print(f'{gb_url} \\n    {text(foot_span)},\\n    {text(bike_span)},\\n    {text(total_span)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294409e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Checkpoint 1\n",
    "\n",
    "* I've retrieved key information about achievements from the dashboard!\n",
    "* I've also retrieved my foot progress percentages!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aebfd48",
   "metadata": {},
   "source": [
    "I want to make a dataframe from this information, but need the shape to match for the rows. I will check the length of each list I want to include to determine their suitability to combine into a df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127816c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_lists = [region_gb_list, region_name_list, region_gps_list, region_foot_distance_list, region_bike_distance_list, region_total_distance_list, region_progress_list]\n",
    "list_names = [\"region_gb_list\", \"region_name_list\", \"region_gps_list\", \"region_foot_distance_list\", \"region_bike_distance_list\", \"region_total_distance_list\", \"region_progress_list\"]\n",
    "\n",
    "for name, region in zip(list_names, region_lists):\n",
    "    print(f'{len(region)} :*: {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d54dd30",
   "metadata": {},
   "source": [
    "Regions number 175 while distances measure 162. I will inspect the data to confirm the additional 13 rows come from time achievements rather than geographic achievements. First, the region information will be combined into a preliminary df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8080eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'GB code': region_gb_list, 'Locations': region_name_list, 'Coordinates': region_gps_list, 'Foot Progress (%)': region_progress_list}\n",
    "df = pd.DataFrame(data)\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8755d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_achievements = df[df['GB code'] == 'N/A']\n",
    "time_achievements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb3fc5d",
   "metadata": {},
   "source": [
    "I confirmed that df contains the month achievements, so I will drop these rows and then merge in the gb-distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5823f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the time achievement rows\n",
    "df.drop(df[df['GB code'] == 'N/A'].index, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a660da",
   "metadata": {},
   "source": [
    "Now the shape of the df matches that of the distance lists, which can be merged to a comprehensive df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3180d13c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#merge the distance data into the preliminary df\n",
    "df['Foot'] = region_foot_distance_list\n",
    "df['Bike'] = region_bike_distance_list\n",
    "df['Total'] = region_total_distance_list\n",
    "df.shape, df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3499b47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#inspect the combined df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d095c7",
   "metadata": {},
   "source": [
    "The dataframe has been successfully created, the desired columns are present, and the information appears correct based on manual inspection of my account info online.\n",
    "\n",
    "The data is all object type. The following updates are needed:\n",
    "\n",
    "Column | Change needed\n",
    "-|-\n",
    "<b>GB code</b> | change to `int` dtype\n",
    "<b>Foot Progress</b> | 1. extract number, 2. change to `float` dtype\n",
    "<b>Locations</b> | none\n",
    "<b>Coordinates</b> | 1. change to series dtype, 2 calculate midpoint, 3. change to `float` dtype\n",
    "<b>Foot</b></b> | split to new columns: distance, points. Trim text and change to `float` dtype\n",
    "<b>Bike</b> | split to new columns: distance, points. Trim text and change to `float` dtype\n",
    "<b>Total distance</b> |split to new columns: distance, points. Trim text and change to `float` dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18da951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the GB code to float\n",
    "df['GB code'] = df['GB code'].astype('float64')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0972cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8658c77",
   "metadata": {},
   "source": [
    "Because the coordinates are composed of a list of lists, I will split into coordinate1 and coordinate2, and then split each of these into longitude and latitude, resaving as 4 new lists and dropping the coordinates and c1, c2 lists used for the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08252a67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#create the c1 and c2 for the two coordinate pairs\n",
    "df[['c1', 'c2']] = pd.DataFrame(df['Coordinates'].tolist(), columns=['c1', 'c2'])\n",
    "df[['c1', 'c2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f49606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split c1 and c2 into longitude and latitude, then compile into the df, dropping the coordinates, c1, and c2 columns used for their generation\n",
    "df[['lon1', 'lat1']] = pd.DataFrame(df['c1'].tolist(), columns=['lon1', 'lat1'])\n",
    "df[['lon2', 'lat2']] = pd.DataFrame(df['c2'].tolist(), columns=['lon2', 'lat2'])\n",
    "\n",
    "df = df.drop(['Coordinates', 'c1', 'c2'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98365f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check datatypes of df column values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44021746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since 'GB code' is float64 dtype, I can count nulls to ensure these were not carried fron the original scrape of date progress awards\n",
    "df['GB code'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccbff09",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Checkpoint 2\n",
    "\n",
    "* `df` contains 9 columns, containing key information on GB code, location, and distances possible\n",
    "* 5 columns are float while 4 are object dtype\n",
    "* I need to:\n",
    "    * extract the distance possible from the text, and convert to float for each max distance column\n",
    "    * scrape [wandrer.earth] for percent completed in each of foot, bike, total (for official, rather than calculated value)\n",
    "    * scrape [wandrer.earth] for distance completed in each of foot, bike, total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af50cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve distance values, drop extra text\n",
    "foot_bike_total = df[['Foot', 'Bike', 'Total']]  # Selecting distance columns\n",
    "\n",
    "for column in foot_bike_total.columns:\n",
    "    new_distance_values = []  # store distance values\n",
    "    new_worth_values = []  # store worth \n",
    "    for region_text in foot_bike_total[column]:\n",
    "        if pd.notnull(region_text):  # Check for non-null values\n",
    "            # Use regular expression to find the distance and worth\n",
    "            dist_match = re.search(r'(\\d+\\.\\d+)\\s*km', str(region_text))\n",
    "            worth_match = re.search(r'(\\d+\\.\\d+)\\s*total', str(region_text))\n",
    "\n",
    "            if dist_match:  #assume all dist match will have worth match\n",
    "                distance_value = dist_match.group(1)\n",
    "                worth_value = worth_match.group(1)\n",
    "                # append found distance to a new list for distance value\n",
    "                new_distance_values.append(distance_value)\n",
    "                # append found worth to a new list for worth value\n",
    "                new_worth_values.append(worth_value)\n",
    "            else:\n",
    "                # If no distance found, list as N/A\n",
    "                new_distance_values.append(\"N/A\")\n",
    "                new_worth_values.append(\"N/A\")\n",
    "        else:\n",
    "            # For null values, list as N/A\n",
    "            new_distance_values.append(\"N/A\")\n",
    "            new_worth_values.append(\"N/A\")\n",
    "\n",
    "    # Update the DataFrame column with modified values\n",
    "    df[column + \" Distance (km)\"] = new_distance_values\n",
    "    df[column + \" Points\"] = new_worth_values\n",
    "\n",
    "# Print the updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d4ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve progress values, drop extra text \n",
    "new_percent_values = []  # store percent values\n",
    "\n",
    "for i in df['Foot Progress (%)']:   # Selecting progress column\n",
    "    if pd.notnull(i):  # Check for non-null values\n",
    "        # Use regular expression to find the distance and worth\n",
    "        match = re.search(r'(\\d+\\.\\d+)\\s*%', str(i))\n",
    "        \n",
    "        if match:\n",
    "            # make the value a float\n",
    "            percent = float(match.group(1))\n",
    "            # append found percent to a new list for percent value\n",
    "            new_percent_values.append(percent)\n",
    "        else:\n",
    "            new_percent_values.append(\"N/A\") # account for null values\n",
    "       \n",
    "    else:\n",
    "        # For null values, list as N/A\n",
    "        new_percent_values.append(\"N/A\")\n",
    "\n",
    "# Update the DataFrame column with modified values\n",
    "df['Foot Progress (%)'] = new_percent_values\n",
    "\n",
    "# Print the updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a8de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba02222d",
   "metadata": {},
   "source": [
    "Drop the Foot Progress (%), Foot, Bike, Total columns, convert distance and worth columns to float dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2deca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#drop the time achievement rows\n",
    "df.drop(['Foot', 'Bike', 'Total'], axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d38228",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = ['Foot Distance (km)', 'Foot Points', 'Bike Distance (km)', 'Bike Points', 'Total Distance (km)', 'Total Points']\n",
    "\n",
    "for col in float_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Convert the specified columns to float64\n",
    "df[float_cols] = df[float_cols].astype('float64')\n",
    "\n",
    "# Check the data types after conversion\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcef417",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Checkpoint 3\n",
    "\n",
    "* `df` contains 13 columns, containing key information on GB code, location, distances, completed percent, and point value\n",
    "* all columns except Locations are float dtype\n",
    "* lat and lon values are seperated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24580a7c",
   "metadata": {},
   "source": [
    "Next, \n",
    "\n",
    "1. IF:\n",
    "    * distance >75%, find <u>the distance required to complete (>99%) region</u>\n",
    "    * distance >50%, find <u>the distance required to move to >75%</u>\n",
    "    * distance >25%, find <u>the distance required to move to >50%</u>\n",
    "    * distance <25%, find <u>the distance required to move to >25%</u>\n",
    "2. find the distance of regions that haven't been started (0% complete and would move to 25%)\n",
    "3. sort by shortest distance to completion for the region\n",
    "4. calculate center longutide and latitude for the lon1+lon2 and lat1+lat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e2a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inprogress_df = df\n",
    "inprogress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d7a5a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inprogress_df['Percent to Level'] = 0.0\n",
    "\n",
    "for index, row in inprogress_df.iterrows():\n",
    "    progress = row['Foot Progress (%)']\n",
    "    if progress >= 99.0:\n",
    "        0\n",
    "    elif progress >= 90.0:\n",
    "        inprogress_df.at[index, 'Percent to Level'] = 99.0 - progress\n",
    "    elif progress >= 75.0:\n",
    "        inprogress_df.at[index, 'Percent to Level'] = 90.0 - progress\n",
    "    elif progress >= 50.0:\n",
    "        inprogress_df.at[index, 'Percent to Level'] = 75.0 - progress\n",
    "    elif progress >= 25.0:\n",
    "        inprogress_df.at[index, 'Percent to Level'] = 50.0 - progress\n",
    "    else:\n",
    "        inprogress_df.at[index, 'Percent to Level'] = 25.0 - progress\n",
    "        \n",
    "inprogress_df.sort_values(by='Percent to Level', ascending=True, inplace=True)\n",
    "inprogress_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'N/A' with NaN for numeric comparison\n",
    "inprogress_df['Foot Distance (km)'] = pd.to_numeric(inprogress_df['Foot Distance (km)'], errors='coerce')\n",
    "\n",
    "# Create conditions to identify 'N/A' values\n",
    "condition_na = inprogress_df['Foot Distance (km)'].isnull()\n",
    "\n",
    "# Calculate 'Distance to Level' based on conditions\n",
    "inprogress_df['Distance to Level'] = np.where(\n",
    "    condition_na,\n",
    "    (inprogress_df['Percent to Level'] / 100) * inprogress_df['Total Distance (km)'],\n",
    "    (inprogress_df['Percent to Level'] / 100) * inprogress_df['Foot Distance (km)']\n",
    ")\n",
    "\n",
    "# Show the modified DataFrame\n",
    "inprogress_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae45c496",
   "metadata": {},
   "source": [
    "Point maximizer is calculated by dividing the foot points possible by the percent to the next level, which should result in larger values for the point maximizer when there are more points available for less distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2f0334",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inprogress_df['point_maximizer'] =  inprogress_df['Foot Points'] / inprogress_df['Percent to Level']\n",
    "inprogress_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1459f5ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#search for initiated regions with leveling opportunities\n",
    "fastest_wins_df = inprogress_df[(inprogress_df['Foot Progress (%)'] <= 99) & (inprogress_df['Foot Progress (%)'] > 0)]\n",
    "\n",
    "# Sorting by 'Foot Distance (km)' and 'Distance to Level'\n",
    "\n",
    "fastest_wins_df = fastest_wins_df.sort_values(by='point_maximizer', ascending=False)\n",
    "\n",
    "# Rounding 'Distance to Level' and converting it to float with 3 decimal places\n",
    "fastest_wins_df['Distance to Level'] = round((fastest_wins_df['Distance to Level']).astype(float), 3)\n",
    "fastest_wins_df = fastest_wins_df[fastest_wins_df['Distance to Level'] < 100]\n",
    "\n",
    "# Displaying the top 20 rows\n",
    "fastest_wins_df = fastest_wins_df.head(20)\n",
    "fastest_wins_df = fastest_wins_df.sort_values(by='Distance to Level', ascending=True)\n",
    "fastest_wins_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac2968f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Checkpoint 4\n",
    "\n",
    "* `fastest_wins_df` shows the top regions for the quickest leveling up, sorted based on maximizing points, but for regions with less than 50km to the leveling event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the average lat and lon values, which should represent a point at the middle of the region area\n",
    "fastest_wins_df['Avg Longitude'] = ((fastest_wins_df['lon1'] + fastest_wins_df['lon2'])/2)\n",
    "fastest_wins_df['Avg Latitude'] = ((fastest_wins_df['lat1'] + fastest_wins_df['lat2'])/2)\n",
    "fastest_wins_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315cacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoDataFrame from latitude and longitude columns\n",
    "geometry = [Point(xy) for xy in zip(fastest_wins_df['Avg Longitude'], fastest_wins_df['Avg Latitude'])]\n",
    "gdf = gpd.GeoDataFrame(fastest_wins_df, geometry=geometry, crs='EPSG:4326')\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea679aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create a GeoDataFrame with Point geometries\n",
    "gdf['geometry'] = gdf.apply(lambda row: Point(row['Avg Longitude'], row['Avg Latitude']), axis=1)\n",
    "\n",
    "# Get a basemap of Metro Vancouver\n",
    "metro_vancouver = gpd.read_file(\"Vancouver-local-area-boundary.geojson\")  # GeoJSON file\n",
    "\n",
    "# Project both GeoDataFrames to the same CRS (coordinate reference system)\n",
    "gdf = gdf.to_crs(metro_vancouver.crs)\n",
    "\n",
    "# Plot the GeoDataFrame with circles representing point_maximizer\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the basemap\n",
    "metro_vancouver.plot(ax=ax, alpha=0.5, color='gray', edgecolor='blue')\n",
    "\n",
    "# Plot the points with color gradient based on 'Distance to Level' and size based on 'point_maximizer'\n",
    "# lighter blue means shorter distance to level, and larger circle means higher points\n",
    "gdf.plot(ax=ax, cmap='Oranges', markersize='point_maximizer', label=\"Locations\", legend=True, edgecolor=\"blue\")\n",
    "\n",
    "# Annotate each point with its 'Locations' name\n",
    "for idx, row in gdf.iterrows():\n",
    "    ax.annotate(row['Locations'], (row['Avg Longitude'], row['Avg Latitude']), textcoords=\"offset points\", xytext=(0,5), ha='center')\n",
    "\n",
    "# Set the axis labels\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bscapstone",
   "language": "python",
   "name": "bscapstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
